---
layout: post
title: "The Singularity"
description: ""
category:
tags: [Artificial Intelligence]
---
{% include JB/setup %}

Although I consider myself a machine learning researcher, I have to say I got all excited about this field because of its relation with Artificial Intelligence. (I consider machine learning to be more about solving "small" practical problems like information retrieval, machine translation, biological data analysis ... whilst AI is the grand search for making machines actually understand the world, I consider AI more about giving machines a deeper semantic understanding of the world.

This post is about a group of enthusiasts called singularitarians whom on one hand I admire but on the other hand approach with skepticism. [Singularitarians](http://en.wikipedia.org/wiki/Singularitarianism) are people who believe that (soon?) there will be technological breakthrough's enabling the creation of smarter-than-human intelligence. The point in time at which this will occur is called the singularity. What I think is great about this movement is that there are [singularitarians](http://en.wikipedia.org/wiki/Ben_Goertzel) who try design architectures that make [strong AI](http://en.wikipedia.org/wiki/Strong_AI) possible. This is absolutely fantastic and it is sad that there are so little opportunities in the academic world for this kind of blue sky research. The reason I am skeptical at points is that a lot of singularity talk ignores the software side of things: there is much ado about peripheral issues and little research that gives us insight into how a conscious machine should work. E.g., Ray Kurzweil (a brilliant thinker by the way!) wrote [a book](http://singularity.com/) about how available computing power will soon match the brain's computational power but hardly gives any insight on what to do with so much hardware.

IEEE Spectrum has a [special issue](http://www.spectrum.ieee.org/singularity) on the singularity with articles by both singularitarians and skeptics. A highly enjoyable read!
